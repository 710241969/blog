# 概述
Kafka是一个分布式流处理系统，流处理系统使它可以像消息队列一样publish或者subscribe消息，分布式提供了容错性，并发处理消息的机制。

# 基本概念
kafka运行在集群上，集群包含一个或多个服务器。kafka把消息存在topic中，每一条消息包含键值（key），值（value）和时间戳（timestamp）。

kafka有以下一些基本概念：
## Producer
消息生产者，就是向kafka broker发消息的客户端。

## Consumer
消息消费者，是消息的使用方，负责消费Kafka服务器上的消息。

## Topic
主题，由用户定义并配置在Kafka服务器，用于建立Producer和Consumer之间的订阅关系。生产者发送消息到指定的Topic下，消息者从这个Topic下消费消息。

## Partition
消息分区，一个topic可以分为多个 partition，每个 partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。

Kafka 可以将主题划分为多个分区（Partition），会根据分区规则选择把消息存储到哪个分区中，只要分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，多个订阅者可以从一个或者多个分区中同时消费数据，以支撑海量数据处理能力。在默认情况下消息分发是轮询均匀分配到 partition 的。

producer 只需要关心消息发往哪个 topic，而 consumer 只关心自己订阅哪个 topic，并不关心每条消息存于整个集群的哪个 broker。 为了性能考虑，如果 topic 内的消息只存于一个 broker，那这个 broker 会成为瓶颈，无法做到水平扩展。所以把 topic 内的数据分布到整个集群就是一个自然而然的设计方式。

> Partition 的引入就是解决水平扩展问题的一个方案。

## Broker
一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。

## Consumer Group
消费者分组，用于归组同类消费者。每个consumer属于一个特定的consumer group，多个消费者可以共同消息一个Topic下的消息，每个消费者消费其中的部分消息，这些消费者就组成了一个分组，拥有同一个分组名称，通常也被称为消费者集群。

## Offset
消息在partition中的偏移量。每一条消息在partition都有唯一的偏移量，消息者可以指定偏移量来指定要消费的消息。

## Leader 和 Follower
一个分区会有多个副本，副本之间是一主(Leader)多从(Follower)的关系，Leader 对外提供服务，这里的对外指的是与客户端程序进行交互，而 Follower 只是被动地同步 Leader 而已，不能与外界进行交互。

当然了，你可能知道在很多其他系统中 Follower 是可以对外提供服务的，比如 MySQL 的从库是可以处理读操作的，但是在 Kafka 中 Follower 只负责消息同步，不会对外提供服务


# 保证消息不丢失
消息的丢失分别从三个方面出发
## 生产者丢失消息的情况
问题
    生产者(Producer) 调用 send 方法发送消息之后，消息可能因为网络问题并没有发送过去
解决
    1. 为了确定消息是发送成功，我们要判断消息发送的结果，Kafka 生产者(Producer) 使用 send 方法发送消息实际上是异步的操作，我们可以通过 get()方法获取调用结果，但是这样也让它变为了同步操作，可以采用为其添加回调函数的形式
    2. Producer 的 retries（重试次数）设置一个比较合理的值，一般是 3. 但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了
## 消费者丢失消息的情况
问题
    当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的问题是，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了
解决
    关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次
## Kafka 弄丢了消息
问题
    假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失
解决
    当我们配置了 unclean.leader.election.enable = false 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性
    * 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
    * 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保leader 挂了还有一个 follower 吧。
    * 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
    * 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。

# 同一个消息重复消费
同一个消息重复消费，根据经验是必然会发生的事情，无论怎么记录消费情况，都有消费完未记录的可能性发生
应当从消费者出发，做好幂等设计，在重复消费相同数据的时候能得到一样的结果

# 消息有序性
1. kafka中，写入一个partion照片中的数据是一定有顺序的
2. kafka中一个消费者消费一个partion的数据，消费者取出数据时，也是有顺序的

消息在被追加到 Partition的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。

一个topic的一个partition只能被一个consumer group中的一个consumer消费，多个consumer消费同一个partition中的数据是不允许的，但是一个consumer可以消费多个partition中的数据。

在Kafka中Partition是真正保存消息的地方，发送的消息都存放在这里。Partition又存在于Topic中，并且一个Topic可以指定多个Partition。
在Kafka中，只保证Partition内有序，不保证Topic所有分区都是有序的，在默认情况下消息分发是轮询均匀分配到 partition 的
所以如果想要保证有序的消息都在同一个 partition 中，有两种方案：
1. 1个Topic（主题）只创建1个Partition(分区)，这样生产者的所有数据都发送到了一个Partition(分区)，保证了消息的消费顺序。但是这么做就不符合 kafka 的设计思想
2. 合理的方案是，生产者在发送消息的时候指定要发送到哪个 Partition
    * 可以直接指定消息要分发的 partition
    * 通过指定 key，有要求顺序消费的消息使用相同的 key，比如可以用我们业务中的全局 ID





