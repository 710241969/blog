___
# 保证消息不丢失
消息的丢失分别从三个方面出发

## 生产者丢失消息的情况
问题
    生产者(Producer) 调用 send 方法发送消息之后，消息可能因为网络问题并没有发送过去
解决
    1. 为了确定消息是发送成功，我们要判断消息发送的结果，Kafka 生产者(Producer) 使用 send 方法发送消息实际上是异步的操作，我们可以通过 get()方法获取调用结果，但是这样也让它变为了同步操作，可以采用为其添加回调函数的形式
    2. Producer 的 retries（重试次数）设置一个比较合理的值，一般是 3. 但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了

## 消费者丢失消息的情况
问题
    当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的问题是，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了
解决
    关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次

## Kafka 弄丢了消息
问题
    假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失
解决
    当我们配置了 unclean.leader.election.enable = false 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性
    * 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
    * 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保leader 挂了还有一个 follower 吧。
    * 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
    * 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。