我叫张三，今年 25 岁，18 年从交大大学毕业，计算机系，目前有 3 年 Java 开发经验（这个是 jd 上
的要求），有 Oracle,MySQL 的开发经验，有 xx 等技术经验（这些经验也是 jd 上的要求）

在项目里，我用过用索引和执行计划等进行数据库调优经验，有 JVM 方面排查 OOM 的经验，大数据
方面，用过 Spark 等框架，分布式组件方面，用过 Redis 和 Dubbo 等，有在 linux 上看日志然后排
查线上问题的经验


在最近的项目里，我用到了 Spring Boot 框架，具体用到了 JPA 组件，数据库用 Oracle，最近的项目
是 xx 系统，用到了敏捷开发模式，在这个项目里，我除了做 coding 外，还做过单元测试，讨论需求
和详细设计等工作，并且最近的项目进度比较紧，我自己感觉还能主动加班，一起和同事们保质保量
地完成项目。

我最近是在 xx 公司（以此突出商业项目）里做了 xx 项目，这个项目的客户方是 xx，已经上线（但如
果是 web 项目面试官大概率会去核对）。这个项目用到了敏捷开发模式（提一下别展开，算抛出个提
问点）， 这个项目组人员是 xx 人，做了 n 个月，我在里面做了 xx 和 xx 模块。

在这个项目里，我们用到了 maven，用 git 来管理代码，用 jira 来管理任务和 bug，用 jenkins 工具
来发布。我还用过 junit 编写过单元测试，我们还用 sonar 来统计代码的测试覆盖度，我们项目经理要
求，只有当“行覆盖率高于 80%”，代码才能提交

我在使用 junit 时，不会敷衍地编写案例，而会根据真实的业务数据来编写案例，并且我还会着重考虑
各种边界情况（这些哪怕初级开发也有本事做到），而且在编写代码时，我会非常注意编码规范，比
23
如定义变量时会让人一看就理解 ，在关键代码地方多写注释，在 if 等条件里不会写太复杂，一个方法
不会写太长，或者你可以再说些其它好的编码规范。而且，一旦遇到我的 bug，我会第一时间跟进，
并会和相关对应的人一起解决掉。

# 工作介绍
我最近是在深圳虾皮信息有限公司，所在的是商户管理团队，参与的东南亚多国，包括越南、泰国、印尼、马来西亚、菲律宾、新加坡等国家的 TOB 业务。
整个团队产研测试共 190 人。用 jira 来管理任务和 bug ，用 jenkins + K8S 工具来做发布和持续交付。
团队包括整个公司都是 Golang 技术栈，用 GRPC 框架微服务框架，数据库用的 MySQL。
我主要负责的是其中的商户钱包及交易支付模块。涉及支付、提现、充值、转账、退款、佣金发放。
TCC 做分布式事务，主要用在充值、提现场景，因为要和银行接口对接。
redis 做分布式锁，以及延迟队列的实现。在每一笔交易单生成后就加入延迟队列，保证交易达到最终状态。
kafka 做系统解耦，包括发货通知和佣金发放。异步插入 kafka，插入成功则删除延迟队列。发货通知和佣金发放都是异步的。一开始是同步的，发货接口的调用性能比较慢，会导致接口超时。而且发货和下单是同一个服务，这里存在服务循环调用的问题。这种情况带来的问题是，举个栗子，如果对方下单接口要加个字段，通知发货接口也要加这个字段，这样服务发布就有顺序依赖。

为什么分十个库？因为出了线上问题，整个 mysql hang 住，全部服务受影响，问题大了，性质就不一样了。做方案，领导也会问，为什么不把库也分了。因为出过问题，解决方案就会采取更加激进的方式了。

# 遇到的问题

## 慢查询
无索引的语句，没有慢查询日志，默认是没有的，需要改参数。通过排查日志，找到响应时间特别长的链路，找到对应的 SQL 语句。
为什么没有索引，因为有个隐式的类型转换。校招生的代码。 code review 没看出来。
在这次事件加急了分库分表的进程。

## 发现并解决了项目中使用的 http 库的一个问题
问题表现：线上大流量并发，上游服务请求下游服务，后续的请求全部出现超时
解决：本地通过开发环境复现，通过 wireshark 抓包，发现超时的请求其实 HTTP 连接过程中 TCP 连接其实很快的，但是还是在 5s 后直接发起关闭，推理是我们系统服务自己的问题。查看服务器 tcp 连接发现有大量正在关闭的连接，都是刚刚请求的连接，数量接近 6w
这个时候就知道大概是什么问题了
查看项目代码，发起 http 请求的地方，使用了一个 http 库，使用了他对象定义的成员变量来设置请求超时时间 5s，通过翻阅源码，发现这样会导致每个请求都建立一个连接，而不是使用连接池，所以在大流量的情况下出现了大量的连接超时
这时候通过用原生 http 库构建了一个超时时间 5s 的 HTTP client 传入这个库，就能使用到默认的连接池，发现连接数没有上来，请求也没有再超时 


gomock gomonkey
在我的推广和带领下，
地图附近商户搜索功能
通过监听 mysql binlog 实时同步商户信息到 ES

通过我的经历，我想您也能看出来，除了在平安银行的业务，其他的经历在金融领域都相对太过稚嫩，我是很想见识更大型更成体系业务和项目，承担更有挑战的任务和职责。

# 工作流程
需求评审——开发做方案设计——开发方案评审——代码开发——QA测试用例评审——自测——showcase并提测——test 环境部署——uat环境部署——UAT验证——发布live

# 项目内容
ArPay counter业务(简称APC)是一个虚拟/电子物品电商平台，向用户售卖电话卡、游戏点卡等虚拟物品，同时提供代缴水电费等服务。APC本身扮演了中间商的角色，卖给用户的电话卡是上游供货商最终提供的

交易支付就是负责其中的，用户下单、支付、资金流转、通知发货，这个流程的业务，包括一些 admin 后台管理操作。
整个架构是：支付模块——钱包模块

一开始交易支付和商品发货管理等一些下游服务是耦合的，一开始支付成功，会调用下游发货接口，但是后面有别的服务要接入，希望能得到我们支付成功的消息，如果每个下游都用接口方式去通知，维护起来就很麻烦，所以接入了 kafka ，解耦上下游服务

钱包模块尽量职责单一，没有引入别的中间件。所以 kafka 消息这一步是在支付模块产生的，而且是异步操作。

延迟队列保证支付钱包连个个模块的最终一致性，同时确保支付成功消息的成功推送。延迟队列是单独自研的一个服务，队列基于 Redis Zset 来实现的，队列任务通过 RPC 调用目标服务的接口触发。在交易模块调用支付模块的建单过程，就往延迟队列插入单号。只有推 kafka 支付成功消息完成才会从队列删除。

延迟队列服务维护了一个 topic 表记录不同的任务，由开发维护，里面有 tpoic（redis 队列 key），目标服务名和方法，任务的处理时间间隔和次数，任务状态。

因为支付服务和钱包服务职责不一样，而且钱包模块很复杂，比较独立，所以两个服务的库是不一样的，这里就会出现数据状态不一致的问题。接口都设计成 TCC 规则。通过延迟队列保证最终一致性。

只要钱包动账成功的，都会走 commit 让整个交易终态走向成功；只要钱包还没完成动账的，都会走 cancel 流程，让整个交易终态走向失败。

一开始没有延迟队列补偿服务，每天由于网络问题、代码 BUG 问题导致的问题单不在少数，需要人工解决处理，也会受到 local 的投诉。通过这一系列完善，整个交易支付服务基础设施基本完备，得到良好运行。

后面就是分库分表的事情了。

# 钱包引擎
钱包引擎在一个库中，水平分表

individual_wallet_tab
个人（Individual）钱包
分表，根据 user_id % 10

fund_movement_tab
资金变动记录表，记录钱包的资金变动
分表，根据 transaction_id / 10,000,000
一笔交易，动账会有四条记录
比如支付 20 元。try 阶段：用户个人钱包 -20 ，用户个人钱包（出）+20；commit 阶段用户个人钱包（出）-20，系统钱包 +20

其他表都是根据钱包流水 id 除一千万向下取整得到分表

因为钱包数据没有查询接口，只有大数据团队进行每天的数据同步

我们提供查询脚本给账务人员，他们通过大数据团队提供的平台进行动账表的查询来进行对账

正因为做得比较好，整个公司的商户要迁移给我们团队去维护，所以进行了一些组织调整，由原来的 APC 商户交易服务团队扩大到 shopee tob 商户管理中台团队


# 分库分表
交易支付层的分库分表，订单号冗余用户id，通过用户 id 取模分库分表
用户 id
mod 10 得到库
mod 100 得到表

分阶段上线
1. 异步写新的拆分库，所有业务都用旧库，每天跑脚本比对昨天的数据是否一致，查漏补缺
2. 异步写旧库，所有业务都用新库，每天跑脚本比对昨天的数据是否一致，查漏补缺，有问题还能及时切换回 1 的状态
3. 完全使用新库，不再写旧库

分库原则
按order_tab当前新增数据量5倍计算，写入数据量为=50w*5=250w/d, 5年总新增数据量=250*365*5=182500，5年后平均每张表写入500w算，需要的表个数

=182500/500=912。

因此总的分表个数可以选择大约1000，分库数量可以大约10个。



# 灰度发布


