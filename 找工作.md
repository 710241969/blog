# 业务介绍

# 工作介绍

我之前就职于在深圳虾皮信息有限公司，所在团队是商户管理团队，主要是管理并服务东南亚多国的入驻商户，包括越南、泰国、印尼、新加坡等国家和地区。我所主要参与的项目，是一项叫ArPay counter业务(简称APC)。这是Shopee为东南亚商户提供的一个虚拟物品售卖平台，主要向用户售卖电话卡、游戏点卡等虚拟物品，同时提供代缴水电费等服务。APC是个TOB场景的售卖平台，扮演了中间商的角色，卖给用户的电话卡是上游供货商最终提供的。
业务模式，就比如顾客到美宜佳，进行话费充值等。
盈利模式就是，卖给消费者 50 元的话费，我们从上游供应商拿货是 48，1 块给商户，1 块我们自己。
我主要负责的是其中的商户钱包及交易支付模块。涉及交易场景包括支付、提现、充值、转账、退款、佣金发放。
商户进行虚拟商品购买，需要先在我们平台进行一个充值，才有足够的余额进行虚拟物品的购买。钱包服务，就是商户充值后这个资金管理的核心服务。记录资金余额，处理资金的流转，记录动账信息等。

整个团队产研测试共 190 人。用 jira 来管理任务和 bug ，用 jenkins + K8S 工具来做发布和持续交付。
团队包括整个公司都是 Golang 技术栈，用 GRPC 框架微服务框架，数据库用的 MySQL。

TCC 做分布式事务，主要用在充值、提现场景，因为要和银行接口对接。
redis 做分布式锁，以及延迟队列的实现。在每一笔交易单生成后就加入延迟队列，保证交易达到最终状态。
kafka 做系统解耦，包括发货通知和佣金发放。异步插入 kafka，插入成功则删除延迟队列。发货通知和佣金发放都是异步的。一开始是同步的，发货接口的调用性能比较慢，会导致接口超时。而且发货和下单是同一个服务，这里存在服务循环调用的问题。这种情况带来的问题是，举个栗子，如果对方下单接口要加个字段，通知发货接口也要加这个字段，这样服务发布就有顺序依赖。

为什么分十个库？因为出了线上问题，整个 mysql hang 住，全部服务受影响，问题大了，性质就不一样了。做方案，领导也会问，为什么不把库也分了。因为出过问题，解决方案就会采取更加激进的方式了。

# 遇到的问题

## 慢查询
分库分表
无索引的语句，没有慢查询日志，默认是没有的，需要改参数。通过排查日志，找到响应时间特别长的链路，找到对应的 SQL 语句。
为什么没有索引，因为有个隐式的类型转换。校招生的代码。 code review 没看出来。更新语句没有使用 id，使用了一个有唯一索引的字段，但是传了个字符串
在这次事件加急了分库分表的进程。

## 发现并解决了项目中使用的 http 库的一个问题
问题表现：线上大流量并发，上游服务请求下游服务，后续的请求全部出现超时
解决：本地通过开发环境复现，通过 wireshark 抓包，发现超时的请求其实 HTTP 连接过程中 TCP 连接其实很快的，但是还是在 5s 后直接发起关闭，推理是我们系统服务自己的问题。查看服务器 tcp 连接发现有大量正在关闭的连接，都是刚刚请求的连接，数量接近 6w
这个时候就知道大概是什么问题了
查看项目代码，发起 http 请求的地方，使用了一个 http 库，使用了他对象定义的成员变量来设置请求超时时间 5s，通过翻阅源码，发现这样会导致每个请求都建立一个连接，而不是使用连接池，所以在大流量的情况下出现了大量的连接超时
这时候通过用原生 http 库构建了一个超时时间 5s 的 HTTP client 传入这个库，就能使用到默认的连接池，发现连接数没有上来，请求也没有再超时 


gomock gomonkey
在我的推广和带领下，
地图附近商户搜索功能
通过监听 mysql binlog 实时同步商户信息到 ES

通过我的经历，我想您也能看出来，除了在平安银行的业务，其他的经历在金融领域都相对太过稚嫩，我是很想见识更大型更成体系业务和项目，承担更有挑战的任务和职责。

# 工作流程
需求评审——开发做方案设计——开发方案评审——代码开发——QA测试用例评审——自测——showcase并提测——test 环境部署——uat环境部署——UAT验证——发布live



# 项目内容

交易支付就是负责其中的，用户下单、支付、资金流转、通知发货，这个流程的业务，包括一些 admin 后台管理操作。
整个架构是：支付模块——钱包模块

一开始交易支付和商品发货管理等一些下游服务是耦合的，一开始支付成功，会调用下游发货接口，但是后面有别的服务要接入，希望能得到我们支付成功的消息，如果每个下游都用接口方式去通知，维护起来就很麻烦，所以接入了 kafka ，解耦上下游服务

钱包模块尽量职责单一，没有引入别的中间件。所以 kafka 消息这一步是在支付模块产生的，而且是异步操作。

延迟队列保证支付钱包连个个模块的最终一致性，同时确保支付成功消息的成功推送。延迟队列是单独自研的一个服务，队列基于 Redis Zset 来实现的，队列任务通过 RPC 调用目标服务的接口触发。在交易模块调用支付模块的建单过程，就往延迟队列插入单号。只有推 kafka 支付成功消息完成才会从队列删除。

延迟队列服务维护了一个 topic 表记录不同的任务，由开发维护，里面有 tpoic（redis 队列 key），目标服务名和方法，任务的处理时间间隔和次数，任务状态。

因为支付服务和钱包服务职责不一样，而且钱包模块很复杂，比较独立，所以两个服务的库是不一样的，这里就会出现数据状态不一致的问题。接口都设计成 TCC 规则。通过延迟队列保证最终一致性。

只要钱包动账成功的，都会走 commit 让整个交易终态走向成功；只要钱包还没完成动账的，都会走 cancel 流程，让整个交易终态走向失败。

一开始没有延迟队列补偿服务，每天由于网络问题、代码 BUG 问题导致的问题单不在少数，需要人工解决处理，也会受到 local 的投诉。通过这一系列完善，整个交易支付服务基础设施基本完备，得到良好运行。

后面就是分库分表的事情了。

# 钱包引擎
钱包引擎在一个库中，水平分表

individual_wallet_tab
个人（Individual）钱包
分表，根据 user_id % 10

fund_movement_tab
资金变动记录表，记录钱包的资金变动
分表，根据 transaction_id / 10,000,000
一笔交易，动账会有记录

比如支付 20 元（和提现一样）。try 用户个人钱包 -20 ，用户个人支出钱包+20；
confirm 阶段，个人支出钱包-20，系统钱包+20；

比如转账 20 元。try A用户个人钱包 -20，A用户个人支出钱包+20； 系统钱包-20，B用户个人收入钱包+20；
confirm 阶段，A用户个人支出钱包-20，系统钱包+20；B用户个人收入钱包-20，B用户个人钱包+20；
锁用户 id 小的

比如充值 20 元。try 阶段，系统钱包-20，用户个人收入钱包+20。
confirm 阶段，用户个人收入钱包-20，用户个人钱包+20。
等于是从系统钱包拨款 20 给用户钱包。

系统钱包单独一张表，两行数据，
一行是系统钱包，可以是负数余额
一行是系统手续费钱包，但这个没有用到因为业务还不收手续费

转账

其他表都是根据钱包流水 id 除一千万向下取整得到分表

因为钱包数据没有查询接口，只有大数据团队进行每天的数据同步

我们提供查询脚本给账务人员，他们通过大数据团队提供的平台进行动账表的查询来进行对账

正因为做得比较好，整个公司的商户要迁移给我们团队去维护，所以进行了一些组织调整，由原来的 APC 商户交易服务团队扩大到 shopee tob 商户管理中台团队

## 为什么要 TCC
首先这个 TCC 接口设计，不仅仅是为了分布式事务
1. 先说一下，分布式事务场景。如充值过程，如果没有 TCC，调用银行接口，银行直接减用户资金的话
如果我们调用银行接口失败，假如是因为网络原因，我们无法确定此时用户在银行的钱是否被扣减，所以只要 try 失败了，就去调用 cancel 接口
2. 不涉及分布式事务的场景。Try 作为交易资金的冻结。只要 try 成功就认为交易成功，交易状态改为 toSuccess，标记让这笔交易最终成功，然后 commit 提交操作；try 失败就认为交易失败，交易状态改为 toFail，实施回滚操作。


# 分库分表
交易支付层的分库分表，订单号冗余用户id，通过用户 id 取模分库分表
用户 id
mod 10 得到库
mod 100 得到表

分阶段上线
1. 异步写新的拆分库，所有业务都用旧库，每天跑脚本比对昨天的数据是否一致，查漏补缺
2. 异步写旧库，所有业务都用新库，每天跑脚本比对昨天的数据是否一致，查漏补缺，有问题还能及时切换回 1 的状态
3. 完全使用新库，不再写旧库

分库原则
按order_tab当前新增数据量5倍计算，写入数据量为=50w*5=250w/d, 5年总新增数据量=250*365*5=182500，5年后平均每张表写入500w算，需要的表个数

=182500/500=912。

因此总的分表个数可以选择大约1000，分库数量可以大约10个。



# 灰度发布


# 最有意思的一个点
就是通过地图去查找商户的功能了。直接让业务量从一天交易30-40w上升到一天60w，并在持续上升。
技术实现上不复杂，但是得到了当地人员和同事的称赞，也直接饶昂业务有了很明显的提升，还是很有成就感，很有意义的。
从技术角度，自己用比如美团，通过地图搜商户，就会去思考，觉得这个功能很厉害，自己做要怎么做呢，但原来自己实际去做，也是能做出来的。








# 挑战
交易支付的业务完整性，和数据一致性的问题
在没有加入延迟队列扫描补偿和kafka消息队列解耦之前，每天有大量的支付失败单，数据不一致单，支付成功未发货的单等等，都需要人工去解决处理，会花费很多时间，也给团队口碑带来一定影响
所以会有后面的一些 TCC 的保证，延迟队列的服务，kafka 的解耦

# 工作的意向
1. 工作地点
2. 电商/金融行业
3. 公司发展状况、前景
4. 岗位的稳定性，现在想在一个公司、一个岗位、在一件事情上耕耘下去，去做沉淀积累
5. 工作和生活的平衡
6. 项目的规划，在公司的定位，是否核心

# 过往工作经历中的(最大)收获
比如从0到1搭建交易支付系统(可以吹牛逼)， 从跟着别人做需求，当变成owner，负责多个大中型项目
1、作为 owner 从0到1搭建交易支付系统，从前是跟着前辈做需求，逐渐去独当一面
2、业务涉及多个国家和地区的业务，需要和其他各个部门打交道，包括其他国家地区的同事去交流、协调、合作，直至完成工作。工作群里、线上会议里会有不同角色、不同国家的同事，和大家沟通协作，推动事情进行，也是很有意思的

# 过去遇到过的最大/难忘的挑战(可以是工作可以是生活)
1、工作、项目的时间管理，如何在短时间保证产出，同时保持质量
2、作为项目负责人，除了技术方案设计落地，还要去协调各端，推进项目的进行，把握进度
3、交易支付系统的不完善，导致前期每天有不少的问题单，卡在中间状态，导致用户的资损和投诉。影响了团队口碑，也是很大压力。

# 过往经历的感悟
跨行业是拓宽业务视野、尝试了不同的行业，了解了不同行业的不同特性
比如金融科技/传统金融银行/电商互联网
传统银行虽然体系化完善稳定，但技术栈比较老旧；
互联网虽然技术成长大，但迭代过快，加上分工很细化，每个人发挥的作用有限，另外互联网纯线上经济的模式近几年不稳定性很大，很多公司依赖融资存活，行业比较动荡

# 提问环节
这个岗位之后是会放在哪个组， 目前那个组的核心工作主要是哪些 
这个岗位人选的预期、看重的一些能力/特质之类的

# 安利意向
1. 电商业务是你目前倾向 也想继续深耕的方向，可以讲讲目前电商行业的一些特性：
1.1 不管是传统行业还是互联网，线上经济在未来都不可或缺；
1.2 电商整体链路长，业务场景复杂度较高，对技术的要求比较高，尤其是促销活动，要面对大流量，是有挑战的，我还是希望在技术这方面能继续成长的
2. 目前也会更加考虑公司平台的发展和业务稳定性，希望能在一个公司比较长期地耕耘、沉淀下去，做好系统技术开发、服务公司业务发展，不想频繁变动，对职业发展也不利


