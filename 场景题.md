___
# 十亿个数的集合和10w个数的集合，如何求它们的交集
HashMap。十亿太多，就存 10w 的就好，遍历十亿，在 10w 的 HashMap 中查找

___
# 两个十亿个数的文件集合，如何求它们的交集
参考 Mysql file_sort
先对一个文件做排序吗可以挑个比较小的，如果内存有限就分而治之，排完序后合并后，再拆分成多个小文件，通过二分查找看是否能找到


___
# 十亿和数找到前100个最大的
1. 可以冒泡排序，遍历一百次就有100个最大的了
2. 可以堆排序，构建最大堆，遍历一遍就能得到
如果说数据实在太大，内存不足，可以分而治之，最后再合并

___
# 假设你只有100M的内存可用，现在有一个大小为1G的文件，里面存放着整数，每个整数用4个字节来存储，要你对这个这个文件中数据进行排序，你有什么解决方案?
数据不重复，数字大小在一定的范围内。如果数据不重复我们可以使用位图来标记相应的数据，在需要输出结果的时候遍历位图即可（此方案较为简单，不在本文的讨论范围内)

数据重复。由于只有100M的内存可用，完全利用这100M内存的情况下意味着我们一次可以对26214400个整数(100 * 1024 * 1024 / 4 ) 进行排序, 这意味着我们要分次读取文件并对读取的内容进行排序，并将每一次排序的结果保存到文件系统中,之后再对这些文件进行合并。
根据缓冲区的大小读入相应的数据量，并把他们转为整数数组，进行排序，并写入文件，重复这一步直到原始数据文件中没有数据可读。
合并这些已排序的文件直到只剩一个文件。
其实就是归并排序文件版

# 给定一个文本，以行为单位，每一行存放了一个IP（IPv4）访问记录，一共存放了10亿次IP记录，请设计一个算法，找出访问次数最多的IP地址。内存限制为1GB
（1）将ip地址放入多个小文件中，保证每种IP只出现在一个文件中
（2）利用hashmap统计每个小文件中IP出现的次数
具体操作：10亿个 IP，一个 IP 32 位也就是 4 个字节，40 亿个字节，我们按 4G 算，内存是 1G 的话，保险起见，我们可以拆成 0-9 十个文件，遍历这 10 亿个 IP ，对 10 取模，得到这个 IP 的文件位置，追加到文件尾部；
每个文件判断是否有超过 1G 的，有的话，可以再 hash，问题不大
访问每个文件，遍历 IP ，放到 HashMap 中，Value 作为出现次数，从 1 开始，遍历完这 10 个文件，就能得到访问次数最多的 IP 地址了

# 给定一个整数数组，找出该数组中满足如下条件的元素并输出：在a[i]前面的所有元素都小于它，排在a[i]后面的所有元素都大于它。比如a[6]={1, 2, 7, 12, 9, 8}，则输出{1, 2, 7}。（给出完整代码）
一、 排序，原数组与排序后数组位置相同的数字则为所需要输出的元素，时间复杂度 O（n²）
二、 遍历原数组，维护一个单调递增子序列数组，然后在后续的源数组遍历中判断子序列最右边的数字是否应该留下，时间复杂度 O(2N) 即 O(N)

# 1分钟内用户上线的数目是60万，如果用户在5分钟内重复上线，就给他发警告，问如何设计？
1 分钟 60w，5 分钟 300w，其实还好
可以维护一个类似 LinkedHashMap 的数据结构，最多只会用来存放 300w 个用户 ID 元素
然后将 5 分钟拆成 300 秒，map 内部维护一个长度为 300 的数组`[0,1,2,3,4,...299]`头尾循环使用每到 299 回到 0，数组用来存储记录这一秒钟内登陆的用户 id，每个桶可以用单向链表维护展开，循环使用时，清除原来这个桶位置上的全部数据，从 map 上删除这些元素

___
# 100万人口的城市，河东这边有80万人，河西这边有20万人，若城市中每天打100万通电话，那么一个公民A（不确定是河东河西）他跨河打电话的概率是多大
每天 100 万个电话，一个电话有两个人，也就是 200w 人次打电话，这里有一个，就是这个人打电话的概率。忽略这个的话，我们假设，每个人都会打两次电话
A 是河东的概率是 0.8，两通电话都是给河东打的概率是，`0.8*0.8*0.8`
A 是河西的概率是 0.2，两通电话都是给河西打的概率是，`0.2*0.2*0.2`
那么电话跨河的概率是 `1 - 0.8*0.8*0.8 - 0.2*0.2*0.2`

# 有三个桶，两个大的可装8斤的水，一个小的可装3斤的水，现在有16斤水装满了两大桶就是8斤的桶，小桶空着，如何把这16斤水分给4个人，每人4斤。没有其他任何工具，4人自备容器，分出去的水不可再要回来
关键在于，如何多弄点 1 斤的水
如果桶是透明的，比较好办，哈哈，下面讨论不透明的情况
3-2-0-0 开局即可








